---
title: "Logistic Regression in R"
subtitle: "Diabetes predition using logistic regression"
author: "Ian Leboo"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
  pdf_document:
    toc: true
    number_sections: true
  word_document:
    toc: true
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Introduction

Logistic Regression is a supervised machine learning techniques used when modeling binary outcomes. It is a type of regression analysis used to predict the probability of a binary outcome based on one or more predictor variables. The outcome variable is typically coded as 0 or 1, where 0 represents the absence of the event and 1 represents the presence of the event.

Read more on logistic regression from my [GitHub repository](https://github.com/StatisticianLeboo/My-Youtube-Channel/blob/main/Machine%20Learning/Supervised%20Learning/Logistic%20Regression/README.md)

The data used in this example is from a [Kaggle](https://www.kaggle.com/datasets/ziya07/diabetes-clinical-dataset100k-rows) repository, and comprises of health and demographic data of 100,000 individuals in the US. We shall predict the outcome of having diabetes (Yes/No) based on a set of predictors. **Note that outcomes may or may not reflect actual medical scenarios but it a great data for practice.**

# Summary of analysis approach

The methodology used in this example is as follows:

1.  Loading the data and required packages

2.  Data cleaning - Checking for missing data - Setting correct variable types - Checking for outliers

3.  Exploratory data analysis

4.  Splitting the data into training and test sets

5.  Building the logistic model using glm

6.  Evaluating the model  - Making predictions - Confusion matrix - ROC curve - F1 score - Accuracy

7.  Use gt summary to create publication friendly model output

8.  IN=ntepret the output of the model

# Loading the data and required packages

```{r}
library(readr)
library(dplyr) # data manipulation
library(gtsummary) # publication friendly tables
library(ggplot2) # data visualization
library(ggthemes) # themes for ggplot2
library(Hmisc)
library(plotly)
library(stringr) # string manipulation

diabetes_dataset <- read_csv("C:/Users/ileboo/OneDrive - CIHEB- KENYA/Documents/My Projects/Youtube content/Machine Learning/Supervised Learning/Logistic Regression/diabetes_dataset.csv")
```

# Data cleaning

```{r}
head(diabetes_dataset)
```

Check Structure of data

```{r}
str(diabetes_dataset)
```

Describe the data

```{r}
describe(diabetes_dataset)
```

For smoking history, lets reduce the classes as follows

-   current -\> Current
-   ever or former or not current -\> Former/Ever
-   No info or never -\> Never

```{r}
diabetes_dataset <- diabetes_dataset %>% 
  dplyr::mutate(
    smoking_history = case_when(
      smoking_history == "current" ~ "Current",
      smoking_history == "ever" | smoking_history ==  "former" | smoking_history == "not current" ~ "Former/Ever",
      smoking_history == "No Info" ~ "Never",
      TRUE ~ as.character(smoking_history)
      ),
    smoking_history = as.factor(str_to_title(smoking_history))

  )
```

No missing data in the dataset

```{r}
colSums(is.na(diabetes_dataset))
```

Drop the last column on clinical notes as it is not needed for the analysis at this point

```{r}
diabetes_dataset <- diabetes_dataset %>% 
  dplyr::select(-clinical_notes)
```

create variable for bmi class - Here is the classification of bmi for children and adults

| **Category** | **Adults (CDC & WHO)** | **Children (CDC & WHO)** |
|------------------|------------------------|-----------------------------|
| **Underweight** | BMI \< 18.5 | Below the 5th percentile |
| **Normal Weight** | BMI 18.5 - 24.9 | 5th to 85th percentile |
| **Overweight** | BMI 25 - 29.9 | 85th to 95th percentile |
| **Obesity** | BMI â‰¥ 30 | 95th percentile or greater |
| **Severe Obesity** | BMI â‰¥ 40 (CDC) | 120% of the 95th percentile or BMI â‰¥ 35 kg/mÂ² (WHO) |

```{r}
diabetes_dataset <- diabetes_dataset %>% 
  dplyr::mutate(
    bmi_class = case_when(
      age < 18 & bmi < 5 ~ "Underweight",
      age >= 18 & bmi < 18.5 ~ "Underweight",
      age < 18 & (bmi >= 5 & bmi < 85) ~ "Normal weight",
      age >= 18 & (bmi >= 18.5 & bmi < 25) ~ "Normal weight",
      age < 18 & (bmi >= 85 & bmi < 95) ~ "Overweight",
      age >= 18 & (bmi >= 25 & bmi < 30) ~ "Overweight",
      age < 18 & (bmi >= 95 & bmi < 120) ~ "Obesity",
      age >= 18 & (bmi >= 30 & bmi < 35) ~ "Obesity",
      age < 18 & bmi >= 120 ~ "Severe Obesity",
      age >= 18 & bmi >= 35 ~ "Severe Obesity"
    )
  )
```

# Exploratory data analysis (EDA)

## Target variable

Distribution of target variable

```{r}
table(diabetes_dataset$diabetes)
```

```{r}
diabetes_dataset %>% 
  group_by(diabetes) %>%
  summarise(total = n()) %>%
  dplyr::mutate(perc = round(total/sum(total) * 100, 2))
```

8.5% of the sample are diabetic - the classes are uneven but we shall proceed with the analysis.

## Summary table of all variables

```{r}
diabetes_dataset %>% 
  # change binary variables to yes and no
  mutate_at(
    dplyr::vars(contains("race"), heart_disease, diabetes),
    funs(as.factor(case_when(
      . == 1 ~ "Yes",
      . == 0 ~ "No",
      TRUE ~ as.character(.)
    )))
  ) %>% 
  tbl_summary(
    missing = "no",
    type = list(
      age ~ "continuous2",
      bmi ~ "continuous2",
      hbA1c_level ~ "continuous2",
      blood_glucose_level ~ "continuous2",
      all_dichotomous() ~ "categorical"
    ),
    statistic = all_continuous() ~ c("{median} ({p25}, {p75})", "{mean}, {sd}", "{min}, {max}")
  ) %>% 
  modify_header(label = "**Variable**") %>% 
  bold_labels()
```

Summary table by response variable

```{r}
diabetes_dataset %>% 
  # change binary variables to yes and no
  mutate_at(
    dplyr::vars(contains("race"), heart_disease, diabetes),
    funs(as.factor(case_when(
      . == 1 ~ "Yes",
      . == 0 ~ "No",
      TRUE ~ as.character(.)
    )))
  ) %>% 
  tbl_summary(
    missing = "no",
    by = diabetes,
    type = list(
      age ~ "continuous2",
      bmi ~ "continuous2",
      hbA1c_level ~ "continuous2",
      blood_glucose_level ~ "continuous2",
      all_dichotomous() ~ "categorical"
    ),
    statistic = all_continuous() ~ c("{median} ({p25}, {p75})", "{mean}, {sd}", "{min}, {max}")
  ) %>% 
  add_overall() %>% 
  modify_spanning_header(all_stat_cols()~"Diabetes") %>% 
  modify_header(label = "**Variable**") %>% 
  bold_labels()
```

Summary table with hypothesis test add p-value

```{r}
diabetes_dataset %>% 
  # change binary variables to yes and no
  mutate_at(
    dplyr::vars(contains("race"), heart_disease, diabetes),
    funs(as.factor(case_when(
      . == 1 ~ "Yes",
      . == 0 ~ "No",
      TRUE ~ as.character(.)
    )))
  ) %>% 
  tbl_summary(
    missing = "no",
    by = diabetes,
    type = list(
      age ~ "continuous2",
      bmi ~ "continuous2",
      hbA1c_level ~ "continuous2",
      blood_glucose_level ~ "continuous2",
      all_dichotomous() ~ "categorical"
    ),
    statistic = all_continuous() ~ c("{median} ({p25}, {p75})", "{mean}, {sd}", "{min}, {max}")
  ) %>% 
  add_overall() %>% 
  add_p() %>%
  modify_spanning_header(all_stat_cols()~"Diabetes") %>% 
  modify_header(label = "**Variable**") %>% 
  bold_labels()
```

## Enrollment by race

Convert the data into long format by race then count

```{r}
library(tidyr)
diabetes_dataset %>% 
  dplyr::select(contains("race")) %>% 
  # rename the columns by extracting the text after the colon
  rename_all(~str_extract(., "(?<=:)[^:]+$")) %>% 
   # pivot the data into long format to only have two columns; source comment
  pivot_longer(cols = everything(), names_to = "race", values_to = "enrolled") %>% 
  # clean the comment column such that if Yes then 1 and if No 0 else NA. also write the source to total case for visibility
  dplyr::mutate(
    race = str_to_title(race)
    ) %>% 
  # group by source and sum by n
  group_by(race) %>%
  summarise(total = sum(enrolled, na.rm = T)) %>% 
  mutate(perc = round(total/sum(total) * 100, 2)) %>% 
  arrange(desc(total)) 
```

## Distribution of blood sugar

### By smoking history

```{r}
ggplot(diabetes_dataset) +
  aes(x = "", y = blood_glucose_level, fill = smoking_history) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1", direction = 1) +
  labs(
    x = "Smoking Status",
    y = "Blood Glucose Level",
    title = "Boxplot for Blood Glucose Level by Smoking History",
    fill = "Smoking History"
  ) +
  theme_bw() +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold",
    hjust = 0.5)
  )

```

### By diabetes status

Individuals with diabetes have higher blood sugar levels

```{r}
diabetes_dataset %>% 
  dplyr::mutate(
    diabetes = ifelse(diabetes == 1, "Yes", "No")
  ) %>% 
  ggplot() +
  aes(x = "", y = blood_glucose_level, fill = diabetes) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  labs(
    x = "Diabetes",
    y = "Blood Glucose Level",
    title = "Boxplot for Blood Glucose Level by Diabetes Status",
    fill = "DIabetes Status"
  ) +
  theme_bw() +
  theme(
    legend.position = "top",
    plot.title = element_text(face = "bold",
    hjust = 0.5)
  )

```

## Number of patients by state

Generate a distinct list of states

Some of the locations recorded are from a district within the states and additionally, some recorded the country name

```{r}
diabetes_dataset %>% 
  dplyr::select(location) %>% 
  distinct(location)
```

For the purpose of visualizing by state, we shall replace the districts with the state names then for United states we shall set to Washington state

```{r}
diabetes_dataset <-  diabetes_dataset %>% 
  dplyr::mutate(
    location = case_when(
      location == "District of Columbia" ~ "Maryland",
      location == "Guam" ~ "Hawaii",
      location == "Puerto Rico" ~ "Florida",
      location == "Virgin Islands" ~ "Florida",
      location == "United States" ~ "Washington", 
      TRUE ~ as.character(location)
  ))
```

Now to plot we shall use Plotly Choropleth functionality using the US state code. Let us first scrape the state codes from the web. To learn more about websraping in R, [watch my previous video](https://youtu.be/YnrVzTCSxoU?si=Em5RkRlv4Tar5dgh)

```{r}
library(rvest)

link = "https://worldpopulationreview.com/state-rankings/state-abbreviations"

page = read_html(link) # convert to html

web_tables<-html_elements(page, "table") # select html elements with *table*

all_tables<- html_table(web_tables) # view tables

us_states <- all_tables[[1]]

us_states <- us_states %>% 
  dplyr::select(State, Abbreviation)
```

Now we can join the two datasets to get the state codes

```{r}
# extract data for enrolment by state
enrolment_by_state <- diabetes_dataset %>% 
  group_by(year, location) %>% 
  summarise(num_patients_enrolled = n()) %>% 
  rename(State = location)

# join the data
enrolment_by_state <- left_join(enrolment_by_state, us_states, by = "State")
```

Finally we map

```{r}
# Prepare data
enrolment_by_state <- enrolment_by_state %>%
  mutate(
    num_patients_enrolled = as.numeric(num_patients_enrolled),
    Abbreviation = toupper(Abbreviation),
    hover = paste0(State, "\n", num_patients_enrolled)
  )

# Updated map layout properties
graph_properties <- list(
  scope = 'usa',
  showland = TRUE,
  landcolor = toRGB("gray95"),
  countrycolor = toRGB("gray80")
)

font = list(
  family = "DM Sans",
  size = 15,
  color = "black"
)

label = list(
  bgcolor = "#EEEEEE",
  bordercolor = "transparent",
  font = font
)

# Create the plot
library(plotly)
enrolment_by_state_graph = plot_geo(enrolment_by_state, frame = ~year) %>% 
  add_trace(
    locations = ~Abbreviation,
    locationmode = 'USA-states',
    z = ~num_patients_enrolled,
    text = ~hover,
    color = ~num_patients_enrolled,
    colorscale = "RdOrYl",
    hoverinfo = "text"
  ) %>% 
  layout(
    geo = graph_properties,
    title = "Patient Enrollment",
    font = font
  ) %>%
  config(displayModeBar = FALSE) %>%
  style(hoverlabel = label) %>%
  colorbar(tickprefix = '')

# Show the plot
enrolment_by_state_graph
```

# Build the logistic regression model

## Prep the data

Drop location and year variable and convert variable types into factors in case of binary variables. Also drop bmi as we have created a categorical variable for this

```{r}
diabetes_dataset <- diabetes_dataset %>%
  dplyr::select(-c(year, location)) %>%
  mutate_at(vars(contains("race"), heart_disease, hypertension, diabetes, gender,smoking_history), as.factor)
```

Create a new variable for race such that it is a single variable with multiple levels instead of multiple binary variables

```{r}
diabetes_dataset <- diabetes_dataset %>% 
  dplyr::mutate(
    race = as.factor(ifelse(
      `race:AfricanAmerican` == 1, "African American", 
      ifelse(`race:Asian` == 1, "Asian", 
             ifelse(`race:Caucasian` == 1, "Caucasian", 
                    ifelse(`race:Hispanic` == 1, "Hispanic", 
                           ifelse(`race:Other` == 1, "Other", NA)
                    )
             )
      )
    )
  )) %>% 
  # drop race variables 
  dplyr::select(-c(`race:AfricanAmerican`:`race:Other`))
```

Convert hypertension and heart disease to yes no instead of 1, 0 as factors

```{r}
diabetes_dataset <- diabetes_dataset %>% 
  mutate_at(
    dplyr::vars(hypertension, heart_disease, diabetes),
    funs(as.factor(case_when(
      . == 1 ~ "Yes",
      . == 0 ~ "No",
      TRUE ~ as.character(.)
    )))
  )
```

Set desired reference groups for categorical variable

```{r}
diabetes_dataset$gender <- relevel(diabetes_dataset$gender, ref = "Female")
diabetes_dataset$hypertension <- relevel(diabetes_dataset$hypertension, ref = "Yes")
diabetes_dataset$heart_disease <- relevel(diabetes_dataset$heart_disease, ref = "Yes")
diabetes_dataset$smoking_history <- relevel(diabetes_dataset$smoking_history, ref = "Never")
diabetes_dataset$race <- relevel(diabetes_dataset$race, ref = "Other")
```

### Splitting the data into test and train

A **70:30 hold-out validation** technique was used to split the data into training and testing sets. This method allows for assessing the model's performance on unseen data

```{r}
set.seed(123) # for reproducibility
splitratio<-sort(sample(nrow(diabetes_dataset), nrow(diabetes_dataset)*.7))
diabetes_dataset_train<-diabetes_dataset[splitratio,]
diabetes_dataset_test<-diabetes_dataset[-splitratio,]
```

## Model Building

Using GLM package

```{r}
diabetes_model <- glm(diabetes ~. , data = diabetes_dataset_train, family = "binomial")
# output the model
summary(diabetes_model)
```

## Evaluate the model

-   The first step involves predicting the probability of having diabetes for each observation in the test set

-   The probabilities are then classified into a binary outcome (Yes/No) based on the threshold of 0.5.

<!-- -->

-   Finally, a **confusion matrix** is generated to evaluate the performance of the model, comparing the predicted outcomes to the actual values in the test dataset.

```{r}
library(caret)
# computing probabilities of the response based on the model
pred1 <- predict(diabetes_model, diabetes_dataset_test, type='response')


# classify the probabilities those below 0.5 to No (0)
predicted_data<- as.factor((ifelse(pred1>=0.5, "Yes", "No")))

# confusion matrix
print(confusionMatrix(predicted_data, diabetes_dataset_test$diabetes))
```

The logistic regression model achieved an accuracy of 96.13%, with a 95% confidence interval of 95.91% to 96.35%, indicating strong performance. The model's sensitivity (99.05%) is high, meaning it effectively identifies individuals with diabetes, while its specificity (64.10%) is lower, indicating it struggles more with detecting non-diabetic individuals. The positive predictive value (96.80%) shows that when the model predicts diabetes, it is usually correct, and the negative predictive value (86.01%) indicates it is reliable when predicting no diabetes. The **Kappa statistic** of 0.7142 suggests substantial agreement with actual outcomes. The model's overall **balanced accuracy** is 81.57%, reflecting its ability to classify both classes effectively. Although the model performs well in detecting diabetes, it could benefit from improved specificity.

**Print F1 score**

```{r}
# install.packages("MLmetrics")
library("MLmetrics")
F1_Score(diabetes_dataset_test$diabetes, predicted_data, positive = NULL)
```

**Likelihood ratio test**

The likelihood ratio test (LRT) compares the fit of two nested models, with the null model being a simpler model and the alternative model being more complex. In this case, the test compares the null model (without predictors) and the fitted logistic regression model. i.e. we assess whether the inclusion of the predictors in the model significantly improves the fit compared to a model with no predictors (the null model).

The test statistic is calculated as the difference between the null deviance and the residual deviance, and the corresponding p-value tests whether the complex model significantly improves the fit over the simpler null model. A p-value less than 0.05 indicates that the more complex model provides a significantly better fit.

```{r}
with(diabetes_model, pchisq(null.deviance-deviance,df.null-df.residual,lower.tail=F))
```

The test returned a p-value of 0, indicating that the fitted model significantly improves the model fit over the null model, suggesting that the included predictors are highly relevant in predicting diabetes.

**ROC curve and AUC score**

```{r}
library(pROC)
simple_roc <- function(labels, scores){
  labels <- labels[order(scores, decreasing=TRUE)]
  data.frame(
    TPR=cumsum(labels)/sum(labels), 
    FPR=cumsum(!labels)/sum(!labels), labels
    )
}

plot(roc(as.numeric(diabetes_dataset_test$diabetes), as.numeric(predicted_data)), main="True Positive Rate vs False Positive Rate", print.auc=TRUE)

simp_roc <- simple_roc(diabetes_dataset_test$diabetes=="TRUE",predicted_data)
with(simp_roc, lines(1 - FPR, TPR, col="blue", lty=2))
```

This model's **AUC of 0.816** indicates it performs **well**, with a strong ability to distinguish diabetic from non-diabetic cases based on the input features. However, there's still some room for improvement â€” potentially by tuning the model or trying other algorithms.

## Bonus - Tabulating the model output in publication friendly format

### Using SjPlot

```{r}
library(sjPlot)
library(sjmisc)
library(sjlabelled)
tab_model(diabetes_model)
```

### Using GT summary

Similar to how we achieved in linear regression, the only difference is that we set *exponentiate = TRUE*

#### Univariate model

```{r}
# Univariate logistic regression model
univ_model<-diabetes_dataset_train %>% 
  tbl_uvregression(
    method = glm,
    y = diabetes,
    method.args = list(family = "binomial"),
    exponentiate = TRUE,
    label = list(
      gender ~ "Gender",
      age ~ "Age",
      hypertension ~ "Hypertension",
      heart_disease ~ "Heart disease",
      race ~ "Race",
      smoking_history ~ "Smoking history",
      bmi ~ "BMI",
      blood_glucose_level ~ "Blood glucose level",
      hbA1c_level ~ "HbA1c level"
      )
    ) %>% 
  add_global_p() %>% 
  # this will update the em-dash in the CI row to Ref.
  modify_table_styling(
    columns = ci,
    rows = reference_row %in% TRUE,
    missing_symbol = "Ref."
  )
```

#### Multivariate logistic model

```{r}
# split the variables into dependent and exploratory
explanatory <- c("gender", "age", "hypertension", "heart_disease", "smoking_history",
                 "bmi", "hbA1c_level", "blood_glucose_level", "race")

dependent = "diabetes"  

# build the multivariate regression model
mv_reg_model <- explanatory %>%  ## begin with vector of explanatory column names
  str_c(collapse = "+") %>%     ## combine all names of the variables of interest separated by a plus
  str_c("diabetes ~ ", .) %>%    ## combine the names of variables of interest with outcome in formula style
  glm(family = "binomial",      ## define type of glm as logistic,
      data = diabetes_dataset_train)          ## define your dataset
#display the results in a table using tbl from mv_reg_model

# tabulate the output
mv_final_table <- tbl_regression(
  mv_reg_model, 
  exponentiate = TRUE,
  label = list(
    gender ~ "Gender",
    age ~ "Age",
    hypertension ~ "Hypertension",
    heart_disease ~ "Heart disease",
    race ~ "Race",
    smoking_history ~ "Smoking history",
    bmi ~ "BMI",
    blood_glucose_level ~ "Blood glucose level",
    hbA1c_level ~ "HbA1c level"
    )
  ) %>% 
  add_global_p() %>% 
  # this will update the em-dash in the CI row to Ref.
  modify_table_styling(
    columns = ci,
    rows = reference_row %in% TRUE,
    missing_symbol = "Ref."
  )
```

#### Combine the tables

```{r}
combined_tab <- tbl_merge(
  tbls = list(univ_model, mv_final_table),                          # combine
  tab_spanner = c("*Univariate (Unadjusted)", "Multivariate (Adjusted)*")) # set header names


combined_tab
```

# Model Interpretation

This section presents the results of a logistic regression model examining the association between selected demographic, clinical, and lifestyle factors and the likelihood of diabetes in a population-based sample of 70,000 individuals. Both univariate (unadjusted) and multivariate (adjusted) odds ratios (OR) are reported.

### Gender

-   Males demonstrated significantly higher odds of diabetes relative to females.
    -   *Adjusted OR = 1.30; 95% CI: 1.20â€“1.41; p \< 0.001*
-   The â€œOtherâ€ category yielded an OR of 0.00, likely reflecting sparse data and resulting in wide or undefined confidence intervals.

### Age

-   Age was positively associated with diabetes.
    -   Each additional year was associated with a 5% increase in the odds of diabetes.\
    -   *Adjusted OR = 1.05; 95% CI: 1.05â€“1.05; p \< 0.001*

### Hypertension

-   Respondents without a history of hypertension had significantly lower odds of diabetes compared to those with hypertension.
    -   *Adjusted OR = 0.46; 95% CI: 0.41â€“0.51; p \< 0.001*

### Heart Disease

-   The absence of heart disease was associated with a protective effect against diabetes.
    -   *Adjusted OR = 0.50; 95% CI: 0.43â€“0.57; p \< 0.001*

### Smoking History

-   Both current and former smokers had elevated odds of diabetes when compared to never smokers.
    -   *Current smokers: Adjusted OR = 1.50; 95% CI: 1.31â€“1.72*\
    -   *Former/Ever smokers: Adjusted OR = 1.28; 95% CI: 1.16â€“1.41*

### Body Mass Index (BMI)

-   BMI was positively associated with diabetes risk.
    -   *Adjusted OR = 1.09; 95% CI: 1.09â€“1.10; p \< 0.001*

### Glycemic Indicators

-   **HbA1c Level** emerged as the strongest predictor in the model.
    -   *Adjusted OR = 10.3; 95% CI: 9.45â€“11.2; p \< 0.001*
-   **Blood Glucose Level** was also significantly associated with increased odds.
    -   *Adjusted OR = 1.03; 95% CI: 1.03â€“1.04; p \< 0.001*

### BMI Classification (Univariate Only)

-   Compared to individuals with normal weight:
    -   *Severe obesity*: OR = 10.9\
    -   *Obesity*: OR = 6.50\
    -   *Overweight*: OR = 3.28\
    -   *Underweight*: OR = 1.55

### Race

-   In the adjusted model, race was not a significant predictor for most categories, with the exception of African Americans who exhibited a modestly elevated risk:
    -   *Adjusted OR = 1.15; 95% CI: 1.01â€“1.31; p = 0.029*

------------------------------------------------------------------------

## ðŸ”‘ Key Takeaways

-   **HbA1c level**, **BMI**, **blood glucose**, **age**, and **hypertension** are statistically significant predictors of diabetes and retained significance after adjustment for confounding.
-   Lifestyle factors such as **smoking history**â€”both current and formerâ€”were independently associated with increased diabetes risk.
-   While **gender** and **race** exhibited associations, the effect sizes were moderate and race was largely non-significant after adjustment.

------------------------------------------------------------------------

## ðŸ“ Summary and Recommendations

### Summary

This logistic regression analysis identified several significant predictors of diabetes in a large, population-based dataset. Glycemic indicators such as **HbA1c** and **blood glucose levels** exhibited the strongest associations with diabetes. Other important risk factors included **older age**, **higher BMI**, **male gender**, **hypertension**, **heart disease**, and **smoking history**. While race showed some variation in risk, most racial differences were not statistically significant in the adjusted models, suggesting that biological and behavioral risk factors may have greater predictive utility in this population.

------------------------------------------------------------------------

### ðŸŽ¯ Recommendations

1.  **Strengthen Community-Based Screening Programs**\
    Leverage BMI, age, and hypertension history for **risk-based screening**â€”especially in settings where laboratory testing (e.g., HbA1c) is inaccessible. This could improve early detection and timely referral.

2.  **Target Obesity in Prevention Campaigns**\
    Given the strong association between BMI and diabetes, **obesity prevention** should remain central to health promotion. Tailored interventions, such as nutrition education and physical activity programs, could be prioritized.

3.  **Integrate Cardiovascular Risk Management**\
    The strong link between **hypertension, heart disease, and diabetes** suggests a need for integrated care models that simultaneously address multiple cardiometabolic risks.

4.  **Tobacco Cessation Interventions**\
    Smokingâ€”both current and formerâ€”was associated with increased odds of diabetes. **Public health efforts should integrate diabetes prevention into tobacco cessation programs**.

5.  **Utilize HbA1c and Blood Glucose in Clinical Settings**\
    These biomarkers showed the **strongest predictive power**. Clinical guidelines should emphasize the use of these indicators for **routine diagnosis and risk stratification**, particularly in high-risk populations.

6.  **Address Gender Disparities**\
    The elevated risk among males indicates a need for **gender-sensitive interventions**, possibly including workplace wellness programs and targeted health education for men.

7.  **Conduct Further Research on Racial Disparities**\
    Though race was not a major determinant in this dataset, **localized or longitudinal studies** may help clarify nuanced racial/ethnic dynamics, especially in different socioeconomic or geographical contexts.
